{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34a4cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24497/1253637130.py:58: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  ax.scatter(inputs_[:, 0], inputs_[:, 1], c=labels, cmap=matplotlib.cm.get_cmap('RdYlBu'))\n"
     ]
    }
   ],
   "source": [
    "import os, sys, numpy, torch, matplotlib.pyplot, matplotlib.cm, ipycanvas, matplotlib.patches\n",
    "\n",
    "sys.path += [os.path.abspath(os.path.join('..')), os.path.abspath(os.path.join('../..'))]  # Allow repository modules to be imported\n",
    "\n",
    "from functools import partial\n",
    "from utils.optimization import initialize\n",
    "from utils.plots import plot_train_loss, plot_samples_and_neurons, plot_weights_norms, draw_figure_into_canvas, save_figure\n",
    "from utils.models import EpsilonNetFullyConnectedNeuralNetwork, FullyConnectedNeuralNetwork\n",
    "from settings.sphere_2d_epsilon_net import get_dataloader, sphere_2d_epsilon_net\n",
    "from experiment import model_summary, plot_neurons_inner_product_to_weights_products, execute_experiment\n",
    "\n",
    "experiment = {\n",
    "    'dataset': 'sphere_2d_epsilon_net',\n",
    "    'epsilon': 0.6,\n",
    "    'net_epsilon': .6,\n",
    "    'seed': 2,\n",
    "    'input_dimension': 2, \n",
    "    'sample_size': 100,  \n",
    "    'batch_size': 100, \n",
    "    'within_cluster_variance': 0.0,\n",
    "    'normalize_inputs':True,\n",
    "    'epochs': 100000,\n",
    "    'learning_rate': .1,\n",
    "    'bias': False,\n",
    "    'name_parameters': ['seed'],\n",
    "    'balance_classes': True,\n",
    "    'initialization_scale': 1.,\n",
    "    'initial_hidden_units': 100,\n",
    "    #'initial_weights': [\n",
    "    #    [[0., 1e-5], [0., -1e-5], [-(.25**.5)*1e-5, -(7.5**.5)*1e-5], [(.5**.5)*1e-5, -(.5**.5)*1e-5], [-(.15**.5)*1e-5, -(.85**.5)*1e-5]]\n",
    "    #],\n",
    "    #'output_layer_initial_weights': [-1e-5, 1e-5, 1e-5, 1e-5, 1e-5]\n",
    "}\n",
    "rotation_matrix = numpy.identity(experiment['input_dimension'])\n",
    "device, generator = initialize(experiment['seed'])\n",
    "train_data = get_dataloader(**experiment, rotation_matrix=rotation_matrix, generator=generator)\n",
    "test_data = get_dataloader(**experiment, rotation_matrix=rotation_matrix, generator=generator)\n",
    "\n",
    "\n",
    "#X =[[2**-.5, 2**-.5], [2**-.5, -2**-.5],] + [[1, 0],] * 2\n",
    "##X =[[1., 1.], [1., -1.],] + [[1., 0.],] * 2\n",
    "#y = [0, 0, ] + [1, ] * 2\n",
    "#\n",
    "#with torch.no_grad():\n",
    "#    tensor_X = torch.Tensor(X)\n",
    "#    tensor_y = torch.Tensor(y)\n",
    "#\n",
    "#dataset = torch.utils.data.TensorDataset(tensor_X, tensor_y)\n",
    "#train_data = test_data = torch.utils.data.DataLoader(dataset, len(X), shuffle=True)\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 10))\n",
    "inputs = []; labels = []\n",
    "for batch_inputs, batch_labels in train_data: inputs.append(batch_inputs); labels.append(batch_labels)\n",
    "inputs, labels = torch.concatenate(inputs), torch.concatenate(labels)\n",
    "inputs_ = numpy.matmul(inputs.detach().cpu().numpy(), rotation_matrix.transpose())\n",
    "ax.hlines(0, -inputs_.max() * 1.1, inputs_.max() * 1.1, color='k')\n",
    "ax.vlines(0, -inputs_.max() * 1.1, inputs_.max() * 1.1, color='k')\n",
    "ax.scatter(inputs_[:, 0], inputs_[:, 1], c=labels, cmap=matplotlib.cm.get_cmap('RdYlBu'))\n",
    "nodes = sphere_2d_epsilon_net(**experiment)\n",
    "#ax.add_patch(matplotlib.patches.Circle([0, 0], 1, color='k', alpha=.1, fill=False))\n",
    "#for node in nodes:\n",
    "#    ax.add_patch(matplotlib.patches.Circle(node, experiment['epsilon'], color='k', alpha=.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1b5ad17-55b7-4878-9be1-bdd85a8e02cb",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4561815d5da94ef5bb92d0ace2201048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=1200, width=1200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.pyplot.ioff()\n",
    "figure, ((input_domain_ax, loss_ax), (parameters_norms_ax, inner_product_to_weights_product_ax)) = matplotlib.pyplot.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "canvas = ipycanvas.Canvas()\n",
    "canvas.width, canvas.height = 1200, 1200\n",
    "canvas.font = '30px arial'\n",
    "canvas.fill_text('Results will appear as processed', canvas.width / 4, canvas.height / 3)\n",
    "\n",
    "plot_samples_and_neurons = partial(plot_samples_and_neurons, ax=input_domain_ax, rotation_matrix=rotation_matrix, dataloader=train_data, label_neurons=True)\n",
    "plot_train_loss = partial(plot_train_loss, ax=loss_ax)\n",
    "plot_weights_norms = partial(plot_weights_norms, ax=parameters_norms_ax)\n",
    "plot_neurons_inner_product_to_weights_products = partial(plot_neurons_inner_product_to_weights_products, ax=inner_product_to_weights_product_ax, aggregate_neurons=True)\n",
    "draw_figure_into_canvas = partial(draw_figure_into_canvas, figure=figure, canvas=canvas)\n",
    "save_figure = partial(save_figure, figure=figure, parameters=experiment, **experiment)\n",
    "\n",
    "canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "761f8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EpsilonNetFullyConnectedNeuralNetwork(**experiment, repeat_nodes=False)\n",
    "plot_samples_and_neurons(model=model)\n",
    "draw_figure_into_canvas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6094b63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00000000e+00,  1.00000000e+00],\n",
       "        [ 3.82683432e-01,  9.23879533e-01],\n",
       "        [ 7.07106781e-01,  7.07106781e-01],\n",
       "        [ 9.23879533e-01,  3.82683432e-01],\n",
       "        [ 1.00000000e+00,  6.12323400e-17],\n",
       "        [ 9.23879533e-01, -3.82683432e-01],\n",
       "        [ 7.07106781e-01, -7.07106781e-01],\n",
       "        [ 3.82683432e-01, -9.23879533e-01],\n",
       "        [ 1.22464680e-16, -1.00000000e+00],\n",
       "        [-3.82683432e-01, -9.23879533e-01],\n",
       "        [-7.07106781e-01, -7.07106781e-01],\n",
       "        [-9.23879533e-01, -3.82683432e-01],\n",
       "        [-1.00000000e+00, -1.83697020e-16],\n",
       "        [-9.23879533e-01,  3.82683432e-01],\n",
       "        [-7.07106781e-01,  7.07106781e-01],\n",
       "        [-3.82683432e-01,  9.23879533e-01]]),\n",
       " tensor([ 1.9891e-11, -1.9891e-11,  1.9891e-11, -1.9891e-11,  1.9891e-11,\n",
       "         -1.9891e-11,  1.9891e-11, -1.9891e-11,  1.9891e-11, -1.9891e-11,\n",
       "          1.9891e-11, -1.9891e-11,  1.9891e-11, -1.9891e-11,  1.9891e-11,\n",
       "         -1.9891e-11], grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes, model(torch.Tensor(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77d780b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m experiment, model, device, generator \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEpsilonNetFullyConnectedNeuralNetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#model_class=FullyConnectedNeuralNetwork,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaving_epochs_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_samples_and_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mplot_train_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_weights_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43mplot_neurons_inner_product_to_weights_products\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_figure_into_canvas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_figure\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model(inputs)\n\u001b[1;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(model\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mflatten())\u001b[38;5;66;03m#.sum(dim=1).shape\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/nns_growth/notebooks/polar_directions/experiment.py:103\u001b[0m, in \u001b[0;36mexecute_experiment\u001b[0;34m(train_data, test_data, model_class, seed, epochs, learning_rate, regularization, train_loss_class, saving_epochs_interval, callbacks_epochs_interval, callbacks_epochs, callbacks, overwrite, **experiment)\u001b[0m\n\u001b[1;32m    101\u001b[0m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    102\u001b[0m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_time)\n\u001b[0;32m--> 103\u001b[0m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    104\u001b[0m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test(train_data, model, accuracy, device))\n\u001b[1;32m    105\u001b[0m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test(test_data, model, train_loss, device))\n",
      "File \u001b[0;32m/workspaces/nns_growth/notebooks/utils/optimization.py:56\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn, device, verbose, calculate_gradients, callback, retain_graph)\u001b[0m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     55\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     57\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(model(X), y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment, model, device, generator = execute_experiment(\n",
    "    **experiment,\n",
    "    train_data=train_data, \n",
    "    test_data=test_data, \n",
    "    model_class=EpsilonNetFullyConnectedNeuralNetwork, \n",
    "    #model_class=FullyConnectedNeuralNetwork,\n",
    "    saving_epochs_interval=experiment['epochs'],\n",
    "    callbacks_epochs=list(range(0, experiment['epochs'], 10000)),\n",
    "    callbacks=[model_summary, plot_samples_and_neurons, \n",
    "               plot_train_loss, plot_weights_norms, \n",
    "               plot_neurons_inner_product_to_weights_products, draw_figure_into_canvas, save_figure],\n",
    "    overwrite=True,\n",
    "    repeat_nodes=False\n",
    ")\n",
    "model(inputs)\n",
    "outputs = model.activations[-1] @ torch.diag(model.output_layer.weight.flatten())#.sum(dim=1).shape\n",
    "gamma = (torch.diag((labels * 2. - 1.).flatten()) @ outputs)\n",
    "gamma_bar = gamma / gamma.sum(dim=1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063d4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
