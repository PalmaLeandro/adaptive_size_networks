{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8546fab-ad68-4215-bfc4-2e954ae8785d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/j68gkt955z57h83crjdjjrg80000gr/T/ipykernel_49452/477873885.py:38: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  ax.scatter(inputs_[:, 0], inputs_[:, 1], c=labels, cmap=matplotlib.cm.get_cmap('RdYlBu_r'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x13b5469e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys, numpy, torch, matplotlib.pyplot, matplotlib.cm\n",
    "\n",
    "sys.path += [os.path.abspath(os.path.join('..')), os.path.abspath(os.path.join('../..'))]  # Allow repository modules to be imported\n",
    "\n",
    "from settings.noisy_xor import get_dataloader\n",
    "from utils.optimization import initialize\n",
    "\n",
    "experiment = {\n",
    "    'dataset': 'linear',\n",
    "    'seed': 1,\n",
    "    'input_dimension': 2, \n",
    "    'sample_size': 5000,  \n",
    "    'batch_size': 5000, \n",
    "    'within_cluster_variance': 10e-16,\n",
    "    'clusters_per_class': 1, \n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'initial_hidden_units': 100,\n",
    "    'initialization_variance': 1e-5,\n",
    "    'bias': False,\n",
    "    'balanced_initialization': True,\n",
    "    'scale_inputs': 0.5,\n",
    "    'shift_inputs': [0, 1]\n",
    "}\n",
    "figures_path = './plots/overparametrization_low_variance_low_separability/'\n",
    "rotation_matrix = numpy.identity(experiment['input_dimension'])\n",
    "device, generator = initialize(experiment['seed'])\n",
    "train_data = get_dataloader(**experiment, rotation_matrix=rotation_matrix, generator=generator)\n",
    "test_data = get_dataloader(**experiment, rotation_matrix=rotation_matrix, generator=generator)\n",
    "inputs = []; labels = []\n",
    "for batch_inputs, batch_labels in train_data: inputs.append(batch_inputs); labels.append(batch_labels)\n",
    "inputs, labels = torch.concatenate(inputs), torch.concatenate(labels)\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 10))\n",
    "inputs_ = numpy.matmul(inputs.detach().cpu().numpy(), rotation_matrix.transpose())\n",
    "ax.hlines(0, -inputs_.max() * 1.1, inputs_.max() * 1.1, color='k')\n",
    "ax.vlines(0, -inputs_.max() * 1.1, inputs_.max() * 1.1, color='k')\n",
    "ax.scatter(inputs_[:, 0], inputs_[:, 1], c=labels, cmap=matplotlib.cm.get_cmap('RdYlBu_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b5ad17-55b7-4878-9be1-bdd85a8e02cb",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import ipycanvas\n",
    "\n",
    "training_canvas, weights_and_biases_canvas, gradients_norms_canvas, input_domain_canvas = ipycanvas.Canvas(), ipycanvas.Canvas(), ipycanvas.Canvas(), ipycanvas.Canvas()\n",
    "training_canvas.width, training_canvas.height = 1200, 600\n",
    "weights_and_biases_canvas.width = 800; weights_and_biases_canvas.height = 800\n",
    "gradients_norms_canvas.width = 1200; gradients_norms_canvas.height = 600\n",
    "input_domain_canvas.width = input_domain_canvas.height = 800\n",
    "training_canvas.font = weights_and_biases_canvas.font = gradients_norms_canvas.font = input_domain_canvas.font = \"30px arial\"\n",
    "args = ('Results will appear as processed', training_canvas.width / 4, training_canvas.height / 3)\n",
    "training_canvas.fill_text(*args); weights_and_biases_canvas.fill_text(*args); gradients_norms_canvas.fill_text(*args); input_domain_canvas.fill_text(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9a6e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d502e5a1b52943119e2e23f9690b06a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=600, width=1200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ac4c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e532bb3cd942449695256aea6eb43738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=800, width=800)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_and_biases_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c361e123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4831c53bee49d38b773cde40bb3522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=600, width=1200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_norms_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28fedb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2ef920214e41018bda56308db4e56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=800, width=800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_domain_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77d780b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LePalma/Documents/git/nns_growth/notebooks/utils/models.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.output_layer.weight.copy_(self.output_layer.weight.sign() * torch.tensor(self.layers[0].weight.norm(dim=1)))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     model_metrics\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mlayers), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_units\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     23\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneurons_weights_norm\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()})\n\u001b[1;32m     25\u001b[0m epochs_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m5\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m10\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m50\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m---> 26\u001b[0m \u001b[43mexecute_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFullyConnectedNeuralNetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaving_epochs_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs_to_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_train_loss_and_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_weights_norm_and_biases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m               \u001b[49m\u001b[43mplot_weights_and_biases_gradient_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_samples_activation_hyperplanes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/nns_growth/notebooks/early_neuron_alignment_bias_extension/experiment.py:42\u001b[0m, in \u001b[0;36mexecute_experiment\u001b[0;34m(train_data, test_data, model_class, seed, epochs, learning_rate, convergence_epsilon, growing_epochs_interval, saving_epochs_interval, callbacks_epochs_interval, callbacks_epochs, callbacks, override, experiment_name_parameters, **experiment)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(training_epochs, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     41\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     44\u001b[0m     train_time \u001b[38;5;241m=\u001b[39m experiment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_time\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/git/nns_growth/notebooks/utils/optimization.py:39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, device, verbose, callback, retain_graph)\u001b[0m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     38\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     40\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(model(X), y)\n",
      "File \u001b[0;32m~/.virtualenvs/nns_growth/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.virtualenvs/nns_growth/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.virtualenvs/nns_growth/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/nns_growth/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/nns_growth/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:139\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from utils.plots import (plot_train_loss_and_accuracy, plot_weights_norm_and_biases, \n",
    "                         plot_weights_and_biases_gradient_norms, plot_samples_activation_hyperplanes)\n",
    "from utils.models import FullyConnectedNeuralNetwork\n",
    "from experiment import execute_experiment\n",
    "\n",
    "save_fig_args = dict(save_figure_path=figures_path, \n",
    "                     figure_name_parameters=['seed', 'within_cluster_variance', 'scale_inputs', 'epoch'])\n",
    "plot_train_loss_and_accuracy = partial(plot_train_loss_and_accuracy, canvas=training_canvas, **save_fig_args)\n",
    "plot_weights_norm_and_biases = partial(plot_weights_norm_and_biases, canvas=weights_and_biases_canvas, **save_fig_args)\n",
    "plot_weights_and_biases_gradient_norms = partial(plot_weights_and_biases_gradient_norms, canvas=gradients_norms_canvas, **save_fig_args)\n",
    "plot_samples_activation_hyperplanes = partial(plot_samples_activation_hyperplanes, canvas=input_domain_canvas, \n",
    "                                              rotation_matrix=rotation_matrix, dataloader=train_data, **save_fig_args)\n",
    "\n",
    "def model_summary(model, model_metrics, epoch, *args, **kwargs):\n",
    "    for layer_index, layer in enumerate(model.layers):\n",
    "        layer_metrics = {'epoch': epoch, 'layer': layer_index, 'hidden_units': layer.weight.shape[0],\n",
    "                         'neurons_weights_norm': layer.weight.norm(dim=1).detach().cpu().tolist()}\n",
    "        if experiment['bias']: layer_metrics.update({'biases': layer.bias.detach().cpu().tolist()})\n",
    "        model_metrics.append(layer_metrics)\n",
    "        \n",
    "    model_metrics.append({'epoch': epoch, 'layer': len(model.layers), 'hidden_units': model.output_layer.weight.shape[1],\n",
    "                          'neurons_weights_norm': model.output_layer.weight.abs().squeeze(dim=0).detach().cpu().tolist()})\n",
    "    \n",
    "epochs_to_plot = list(range(10)) + list(range(10, 50, 5)) + list(range(50, 100, 10)) + list(range(100, 500, 50)) + list(range(500, 1000, 100))\n",
    "execute_experiment(\n",
    "    **experiment,\n",
    "    experiment_name_parameters=['seed'],\n",
    "    train_data=train_data, \n",
    "    test_data=test_data, \n",
    "    model_class=FullyConnectedNeuralNetwork,\n",
    "    saving_epochs_interval=experiment['epochs'],\n",
    "    callbacks_epochs=epochs_to_plot,\n",
    "    callbacks=[model_summary, plot_train_loss_and_accuracy, plot_weights_norm_and_biases, \n",
    "               plot_weights_and_biases_gradient_norms, plot_samples_activation_hyperplanes],\n",
    "    override=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ea252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "\n",
    "sys.path += [os.path.abspath(os.path.join('..')), os.path.abspath(os.path.join('../..'))]  # Allow repository modules to be imported\n",
    "\n",
    "from utils.persistance import check_path\n",
    "\n",
    "epochs_to_plot = list(range(10)) + list(range(10, 50, 5)) + list(range(50, 100, 10)) + list(range(100, 500, 50)) + list(range(500, 1000, 100))\n",
    "notebook_name = 'overparametrization_high_variance_low_separability'\n",
    "animation_path = f'./animations/{notebook_name}'\n",
    "check_path(animation_path)\n",
    "figures_path = f'./plots/{notebook_name}/'\n",
    "plot_names = [directory for directory in os.listdir(figures_path) if '.' not in directory]\n",
    "for plot in plot_names:\n",
    "    check_path(os.path.join(animation_path, plot))\n",
    "    for file in [fig_file for fig_file in os.listdir(os.path.join(figures_path, plot)) if 'ds_store' not in fig_file.lower()]:\n",
    "        epoch = int(file.split('_')[-1].split('.')[0])\n",
    "        if epoch in epochs_to_plot:\n",
    "            shutil.copy(os.path.join(figures_path, plot, file), os.path.join(animation_path, plot, f'animation{epochs_to_plot.index(epoch)}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6e298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
