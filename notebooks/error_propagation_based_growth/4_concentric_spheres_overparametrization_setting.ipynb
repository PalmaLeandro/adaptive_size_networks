{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb264f59-d0b4-4a3a-bab6-2754b989d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, numpy, torch, matplotlib.pyplot\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))  # Allow repository modules to be imported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f41de7-34b3-4fec-bf4c-295f7e8b45ff",
   "metadata": {},
   "source": [
    "# Concentric spheres data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8546fab-ad68-4215-bfc4-2e954ae8785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1956d4670>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings.concentric_spheres import get_dataloader\n",
    "\n",
    "data_setting = {\n",
    "    'seed': 1234,\n",
    "    'input_dimension': 2, \n",
    "    'spheres_dimension': 2, \n",
    "    'number_of_spheres': 4, \n",
    "    'sample_size': 5000, \n",
    "    'margin': 0.3\n",
    "}\n",
    "\n",
    "data, rotation_matrix = get_dataloader(**data_setting)\n",
    "_, (inputs, labels) = next(enumerate(data))\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(10, 10))\n",
    "inputs_ = numpy.matmul(inputs.detach().cpu().numpy(), rotation_matrix.transpose())\n",
    "ax.scatter(inputs_[:, 0], inputs_[:, 1], c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af03851b-250c-4b33-95df-681aec122c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setting = {\n",
    "    'epochs': 10000,\n",
    "    'learning_rate': 0.05,\n",
    "    'batch_size': data_setting['sample_size'],\n",
    "    'hidden_units': 2,\n",
    "    'bias': True,\n",
    "    'initialization_variance': 1. / data_setting['input_dimension'] ** 1.2\n",
    "}\n",
    "\n",
    "class TwoLayerNeuralNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension:int, hidden_units:int, initialization_variance:float=1., bias:bool=True, *args, **kwargs):\n",
    "        super(TwoLayerNeuralNet, self).__init__()\n",
    "        self.device = 'cpu'\n",
    "        self.hidden_units = hidden_units\n",
    "        self.input_dimension = input_dimension\n",
    "        if hidden_units % 2 == 1:\n",
    "            hidden_units -= 1\n",
    "            print(f'Only even number of hidden units allowed. Switching to hidden units = {hidden_units}') \n",
    "\n",
    "        self.input_layer = torch.nn.Linear(input_dimension, hidden_units, bias=bias)\n",
    "        #torch.nn.init.normal_(self.input_layer.weight, std=initialization_variance ** 0.5)\n",
    "        #if bias: self.input_layer.bias.data = torch.zeros(input_dimension, requires_grad=True)\n",
    "\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        output_layer_weights = [1. / hidden_units ** 0.5] * (hidden_units // 2) + [-1. / hidden_units ** 0.5] * (hidden_units // 2)\n",
    "        self.output_layer_weights = torch.tensor(output_layer_weights)\n",
    "\n",
    "        self.dummy_variable1 = torch.zeros(hidden_units, hidden_units, requires_grad=True)\n",
    "        self.dummy_variable1.retain_grad()\n",
    "\n",
    "        self.dummy_variable2 = torch.zeros(input_dimension, input_dimension, requires_grad=True)\n",
    "        self.dummy_variable2.retain_grad()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #dummy_term2 = (\n",
    "        #    x.reshape(-1, self.input_dimension, 1).bmm(x.mm(self.dummy_variable2).reshape(-1, 1, self.input_dimension))\n",
    "        #)\n",
    "        self.pre_activations = self.input_layer(x).requires_grad_() #+ dummy_term2\n",
    "        self.pre_activations.retain_grad()\n",
    "        self.activations = self.activation(self.pre_activations).requires_grad_()\n",
    "        self.activations.retain_grad()\n",
    "        #dummy_term1 = (\n",
    "        #    self.activations.unsqueeze(1).bmm(self.activations.mm(self.dummy_variable1)\n",
    "        #        .reshape(-1, self.hidden_units, 1)).reshape(-1)\n",
    "        #)\n",
    "        output = torch.matmul(self.activations, self.output_layer_weights) #+ dummy_term1\n",
    "        return output.unsqueeze(1)\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.output_layer_weights = self.output_layer_weights.to(device)\n",
    "        self.dummy_variable1 = self.dummy_variable1.to(device)\n",
    "        self.dummy_variable1.retain_grad()\n",
    "        self.dummy_variable2 = self.dummy_variable2.to(device)\n",
    "        self.dummy_variable2.retain_grad()\n",
    "        self.device = device\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b5ad17-55b7-4878-9be1-bdd85a8e02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipycanvas\n",
    "\n",
    "training_canvas, gradients_norms_canvas, input_domain_canvas = ipycanvas.Canvas(), ipycanvas.Canvas(), ipycanvas.Canvas()\n",
    "training_canvas.width = training_canvas.height = 800\n",
    "gradients_norms_canvas.width = 1200; gradients_norms_canvas.height = 600\n",
    "input_domain_canvas.width = input_domain_canvas.height = 800\n",
    "training_canvas.font = gradients_norms_canvas.font = input_domain_canvas.font = \"30px arial\"\n",
    "args = ('Results will appear as processed', training_canvas.width / 4, training_canvas.height / 3)\n",
    "training_canvas.fill_text(*args); gradients_norms_canvas.fill_text(*args); input_domain_canvas.fill_text(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6eb3ab-e384-4f3b-8a58-bdd94aed2448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592b20c5c7534897964406e6a1931287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=800, width=800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6177433a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb567b51db1742cf93943967ecb75027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=600, width=1200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_norms_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ee36ad-bca0-4205-840f-6842e661017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd7b48a3e13431dad65e7cba42a8c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=800, width=800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_domain_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3189a0f4-e94c-4271-aea1-a28bd336434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.optimization import initialize, train, test, Accuracy\n",
    "from plots import plot_experiment, plot_gradients_norms, plot_samples_and_model_activation_and_neurons_hyperplanes\n",
    "\n",
    "plots_epochs_interval = 100\n",
    "\n",
    "experiment = {\n",
    "    **data_setting,\n",
    "    **model_setting,\n",
    "    'train': 'Accuracy',\n",
    "    'test': 'Accuracy',\n",
    "    'train_time': 'seconds',\n",
    "    'models_runs': []\n",
    "}\n",
    "\n",
    "device = initialize(experiment['seed'])\n",
    "train_data, rotation_matrix = get_dataloader(**experiment) \n",
    "test_data = get_dataloader(**experiment, rotation_matrix=rotation_matrix)\n",
    "model = TwoLayerNeuralNet(**experiment).to(device)\n",
    "train_loss, test_loss = torch.nn.BCEWithLogitsLoss(), Accuracy\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=experiment['learning_rate'])\n",
    "run = {\n",
    "    'distinction': '1',\n",
    "    'train': [test(train_data, model, test_loss, device)],\n",
    "    'train_time': [0],\n",
    "    'test': [test(test_data, model, test_loss, device, verbose=False)]\n",
    "}\n",
    "experiment['models_runs'].append(run)\n",
    "\n",
    "def gradients_summary(model, *args, epoch_frequency=1):\n",
    "    epoch = len(run.get('train', []))\n",
    "    if epoch == 0 or epoch % epoch_frequency != 0: return\n",
    "\n",
    "    sample_size = experiment['sample_size']\n",
    "    pre_activations_gradients_average_norm = model.pre_activations.grad.mean(dim=0).norm().item() * sample_size\n",
    "    run['pre_activations_gradients_average_norm'] = \\\n",
    "        run.get('pre_activations_gradients_average_norm', []) + [pre_activations_gradients_average_norm]\n",
    "    \n",
    "    activations_gradients_average_norm = model.activations.grad.mean(dim=0).norm().item() * sample_size\n",
    "    run['activations_gradients_average_norm'] = \\\n",
    "        run.get('activations_gradients_average_norm', []) + [activations_gradients_average_norm]\n",
    "\n",
    "    pre_activations_average_gradient_norm = model.pre_activations.grad.norm(dim=1).mean().item() * sample_size\n",
    "    run['pre_activations_average_gradient_norm'] = \\\n",
    "        run.get('pre_activations_average_gradient_norm', []) + [pre_activations_average_gradient_norm]\n",
    "    \n",
    "    activations_average_gradient_norm = model.activations.grad.norm(dim=1).mean().item() * sample_size\n",
    "    run['activations_average_gradient_norm'] = \\\n",
    "        run.get('activations_average_gradient_norm', []) + [activations_average_gradient_norm]\n",
    "\n",
    "plot_samples_and_model_activation_and_neurons_hyperplanes(dataloader=train_data, model=model, rotation_matrix=rotation_matrix, \n",
    "                                                          **experiment, canvas=input_domain_canvas)\n",
    "\n",
    "for epoch in range(1, experiment['epochs'] + 1):\n",
    "    start_time = time.time()\n",
    "    train(train_data, model, train_loss, optimizer, device, verbose=False, callback=gradients_summary)\n",
    "    end_time = time.time()\n",
    "    train_time = run['train_time'][-1] + end_time - start_time\n",
    "    train_loss_value = test(train_data, model, test_loss, device, verbose=False)\n",
    "    test_loss_value = test(test_data, model, test_loss, device, verbose=False)\n",
    "    run['train'].append(train_loss_value)\n",
    "    run['train_time'].append(train_time)\n",
    "    run['test'].append(test_loss_value)\n",
    "    if epoch % plots_epochs_interval == 0 or epoch == experiment['epochs']:\n",
    "        plot_experiment(experiment, training_canvas)\n",
    "        plot_gradients_norms(run, canvas=gradients_norms_canvas)\n",
    "        plot_samples_and_model_activation_and_neurons_hyperplanes(\n",
    "            dataloader=train_data, model=model, rotation_matrix=rotation_matrix, **experiment, \n",
    "            canvas=input_domain_canvas\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdc78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
